import asyncio
import os
import tempfile
import gradio as gr
from textwrap import dedent
from agno.agent import Agent
from agno.tools.mcp import MCPTools
from agno.models.nebius import Nebius
from mcp import ClientSession
from mcp.client.sse import sse_client
from dotenv import load_dotenv
import base64
import difflib
import re
import subprocess
import sys
import shutil
import time
import aiohttp
import logging
import signal
import socket
import json


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def extract_json_payload(raw: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–≤—ã–π JSON –æ–±—ä–µ–∫—Ç {...} –∏–∑ —Å—Ç—Ä–æ–∫–∏, —É–¥–∞–ª—è—è Markdown-—Ä–∞–∑–º–µ—Ç–∫—É –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç.
    """
    # –£–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ <think>
    raw = re.sub(r"<think>.*?</think>", "", raw, flags=re.DOTALL).strip()
    
    # –£–±–∏—Ä–∞–µ–º markdown –±–ª–æ–∫–∏
    raw = re.sub(r"```json\s*", "", raw)
    raw = re.sub(r"```", "", raw)
    
    # –ò—â–µ–º –ø–µ—Ä–≤—ã–π '{' –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π '}'
    start = raw.find("{")
    end = raw.rfind("}")
    
    if start != -1 and end != -1 and end > start:
        json_candidate = raw[start:end + 1]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å JSON –ø–µ—Ä–µ–¥ –≤–æ–∑–≤—Ä–∞—Ç–æ–º
        try:
            json.loads(json_candidate)
            return json_candidate
        except json.JSONDecodeError:
            # –ï—Å–ª–∏ JSON –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É
            logger.warning("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π JSON –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É")
            return raw
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç—Ä–æ–∫—É
    return raw

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–µ—Å—Å–∏–π
MCP_WRAPPERS = {}

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()
api_key = os.getenv("NEBIUS_API_KEY")
if not api_key:
    raise ValueError("NEBIUS_API_KEY not found in .env file")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è MCP —Å–µ—Ä–≤–µ—Ä–æ–≤ (–¥–ª—è Docker —Å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è)
BANDIT_PORT = os.getenv('BANDIT_INTERNAL_PORT', '7861')
DETECT_SECRETS_PORT = os.getenv('DETECT_SECRETS_INTERNAL_PORT', '7862')
PIP_AUDIT_PORT = os.getenv('PIP_AUDIT_INTERNAL_PORT', '7863')
CIRCLE_TEST_PORT = os.getenv('CIRCLE_TEST_INTERNAL_PORT', '7864')
SEMGREP_PORT = os.getenv('SEMGREP_INTERNAL_PORT', '7865')

MCP_SERVERS = {
    "bandit": {
        "url": f"http://bandit-security-scanner:{BANDIT_PORT}/gradio_api/mcp/sse",
        "description": "Python code security analysis",
        "port": int(BANDIT_PORT)
    },
    "detect_secrets": {
        "url": f"http://detect-secrets-scanner:{DETECT_SECRETS_PORT}/gradio_api/mcp/sse",
        "description": "Secret detection in code",
        "port": int(DETECT_SECRETS_PORT)
    },
    "pip_audit": {
        "url": f"http://pip-audit-scanner:{PIP_AUDIT_PORT}/gradio_api/mcp/sse",
        "description": "Python package vulnerability scanning",
        "port": int(PIP_AUDIT_PORT)
    },
    "circle_test": {
        "url": f"http://circle-test-scanner:{CIRCLE_TEST_PORT}/gradio_api/mcp/sse",
        "description": "Security policy compliance checking",
        "port": int(CIRCLE_TEST_PORT)
    },
    "semgrep": {
        "url": f"http://semgrep-scanner:{SEMGREP_PORT}/gradio_api/mcp/sse",
        "description": "Advanced static code analysis",
        "port": int(SEMGREP_PORT)
    }
}

def check_port(port: int) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø–æ—Ä—Ç–∞"""
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    try:
        result = sock.connect_ex(('127.0.0.1', port))
        return result == 0
    finally:
        sock.close()

def signal_handler(signum, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è"""
    logger.info("–ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è, –∑–∞–∫—Ä—ã–≤–∞–µ–º —Å–µ—Ä–≤–µ—Ä—ã...")
    sys.exit(0)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def generate_simple_diff(original_content: str, updated_content: str, file_path: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–π diff –º–µ–∂–¥—É –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
    """
    diff_lines = list(difflib.unified_diff(
        original_content.splitlines(keepends=True),
        updated_content.splitlines(keepends=True),
        fromfile=f"{file_path} (original)",
        tofile=f"{file_path} (modified)",
        n=3
    ))
    if not diff_lines:
        return "No changes detected."
    added_lines = sum(1 for l in diff_lines if l.startswith("+") and not l.startswith("+++"))
    removed_lines = sum(1 for l in diff_lines if l.startswith("-") and not l.startswith("---"))
    diff_content = "".join(diff_lines)
    stats = f"\nüìä Changes: +{added_lines} additions, -{removed_lines} deletions"
    return diff_content + stats

async def check_server_availability(url: str, max_retries: int = 5, delay: float = 5.0) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å MCP —Å–µ—Ä–≤–µ—Ä–∞ —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º–∏ —Ç–∞–π–º–∞—É—Ç–∞–º–∏"""
    logger.debug(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞: {url}")
    for i in range(max_retries):
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=30) as response:
                    if response.status == 200:
                        logger.info(f"–°–µ—Ä–≤–µ—Ä {url} –¥–æ—Å—Ç—É–ø–µ–Ω")
                        return True
        except Exception as e:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {i+1}/{max_retries} –Ω–µ —É–¥–∞–ª–∞—Å—å: {str(e)}")
        await asyncio.sleep(delay)
    logger.error(f"–°–µ—Ä–≤–µ—Ä {url} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫")
    return False

async def init_all_tools():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global MCP_WRAPPERS
    
    try:
        # –°–æ–∑–¥–∞–µ–º SSE –∫–ª–∏–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
        for name, cfg in MCP_SERVERS.items():
            async with sse_client(cfg["url"]) as (read, write):
                async with ClientSession(read, write) as session:
                    MCP_WRAPPERS[name] = MCPTools(session=session)
            
        logger.info("–í—Å–µ MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤: {str(e)}")
        raise

async def run_mcp_agent(message, server_name):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ MCP —Å–µ—Ä–≤–µ—Ä–∞"""
    logger.info(f"–ó–∞–ø—É—Å–∫ MCP –∞–≥–µ–Ω—Ç–∞ –¥–ª—è {server_name}")
    
    if not api_key:
        logger.error("Nebius API key –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ")
        return "Error: Nebius API key not found in .env file"
    
    if server_name not in MCP_SERVERS:
        logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π MCP —Å–µ—Ä–≤–µ—Ä: {server_name}")
        return f"Error: Unknown MCP server {server_name}"
    
    if server_name not in MCP_WRAPPERS:
        logger.error(f"MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç {server_name} –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        return f"Error: MCP tool {server_name} not initialized"
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –∏–∑ –∫—ç—à–∞
        mcp_tools = MCP_WRAPPERS[server_name]
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞
        if server_name == "detect_secrets":
            tool_args = {
                "code_input": message,
                "scan_type": "code",
                "base64_limit": 4.5,
                "hex_limit": 3.0,
                "exclude_lines": ".*test.*|.*example.*",
                "exclude_files": ".*test.*|.*example.*",
                "exclude_secrets": ".*test.*|.*example.*",
                "word_list": "password,secret,key,token,api_key,credential",
                "output_format": "json"
            }
        elif server_name == "bandit":
            tool_args = {
                "code_input": message,
                "scan_type": "code",
                "severity_level": "high",
                "confidence_level": "high",
                "output_format": "json"
            }
        elif server_name == "circle_test":
            tool_args = {
                "prompt": message,
                "policies": {
                    "1": "Presence of SPDX-License-Identifier with an ID not in the approved list, or missing SPDX tag in top-level LICENSE file.",
                    "2": "Presence of plaintext credentials (passwords, tokens, keys) in configuration files (YAML, JSON, .env, etc.).",
                    "3": "Presence of TODO or FIXME tags in comments inside non-test production code files.",
                    "4": "Presence of any string literal starting with http:// not wrapped in a validated secure-client.",
                    "5": "Presence of logging statements that output sensitive data (user PII, private keys, passwords, tokens) without masking or hashing.",
                    "6": "Presence of calls to deprecated or outdated APIs (functions or methods marked as deprecated).",
                    "7": "Presence of subprocess or os.system calls that embed unsanitized user input into shell commands (e.g., f\"rm {user_input}\" with shell=True).",
                    "8": "Presence of open(), read(), write(), or similar file operations using a path directly derived from user input without normalization or path-traversal checks (e.g., open(f\"{user_input}.txt\")).",
                    "9": "Presence of SQL queries built using string concatenation with user input instead of parameterized queries or ORM methods.",
                    "10": "Presence of string literals matching absolute filesystem paths (e.g., \"/home/...\" or \"C:\\\\...\") rather than relative paths or environment variables.",
                    "11": "Presence of hostnames or URLs containing \"prod\", \"production\", or \"release\" that reference production databases or services in non-test code.",
                    "12": "Presence of dependencies in lock files (Pipfile.lock or requirements.txt) without exact version pins (using version ranges like \">=\" or \"~=\" without a fixed version)."
                }
            }
        else:
            tool_args = {"code_input": message}
        
        # –°–æ–∑–¥–∞–µ–º –∞–≥–µ–Ω—Ç–∞
        agent = Agent(
            tools=[mcp_tools],
            instructions=dedent("""\
                You are an intelligent security assistant with access to MCP tools.
                - Automatically select and invoke the appropriate tool(s) based on the user's request.
                - Always choose the highest intensity settings available.
                - If the user specifies particular checks, focus on those.
                - Return ONLY the raw JSON output from the tool‚Äîno Markdown fences, no commentary, nothing else.
                - Do not add any explanations or formatting around the JSON output.
            """),
            markdown=False,  # –û—Ç–∫–ª—é—á–∞–µ–º Markdown –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —á–∏—Å—Ç–æ–≥–æ JSON
            show_tool_calls=True,
            model=Nebius(
                id="Qwen/Qwen3-30B-A3B-fast",
                api_key=api_key
            )
        )
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
        formatted_message = {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": f"Please analyze this code using {server_name} with the following parameters: {tool_args}"
                }
            ]
        }
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        response = await agent.arun(formatted_message)
        logger.info(f"–£—Å–ø–µ—à–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è {server_name}")
        
        # –û—á–∏—â–∞–µ–º –æ—Ç–≤–µ—Ç –∏ –∏–∑–≤–ª–µ–∫–∞–µ–º JSON
        clean_response = extract_json_payload(response.content)
        return clean_response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è {server_name}: {str(e)}")
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –¥–ª—è –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏
        error_response = {
            "success": False,
            "error": f"Error running {server_name}: {str(e)}",
            "results": {}
        }
        return json.dumps(error_response, ensure_ascii=False)

async def run_fix_agent(message):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–¥–∞"""
    if not api_key:
        return "Error: Nebius API key not found in .env file"
    
    agent = Agent(
        tools=[],
        instructions=dedent("""\
            You are an intelligent code refactoring assistant.
            Based on the vulnerabilities detected, propose a corrected version of the code.
            Return only the full updated source code, without any additional commentary or markup.
        """),
        markdown=False,
        show_tool_calls=False,
        model=Nebius(
            id="Qwen/Qwen3-30B-A3B-fast",
            api_key=api_key
        )
    )
    try:
        response = await agent.arun(message)
        return response.content
    except Exception as e:
        return f"Error proposing fixes: {e}"

async def process_file(file_obj, custom_checks, selected_servers):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö MCP —Å–µ—Ä–≤–µ—Ä–æ–≤"""
    if not file_obj:
        return "", "", ""
    
    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        temp_dir = tempfile.gettempdir()
        file_path = os.path.join(temp_dir, file_obj.name)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –∏–∑ –æ–±—ä–µ–∫—Ç–∞ Gradio
        with open(file_obj.name, 'r', encoding='utf-8') as f:
            file_content = f.read()
            
        with open(file_path, "w", encoding='utf-8') as f:
            f.write(file_content)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–µ—Ä–æ–≤
        if custom_checks:
            user_message = (
                f"Please analyze this code for {custom_checks}, "
                f"using the most comprehensive settings available:\n\n{file_content}"
            )
        else:
            user_message = (
                f"Please perform a full vulnerability and security analysis on this code, "
                f"selecting the highest intensity settings:\n\n{file_content}"
            )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = {
            server: asyncio.create_task(run_mcp_agent(user_message, server))
            for server in selected_servers
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        raw_outputs = {
            server: re.sub(r"<think>.*?</think>", "", await task, flags=re.DOTALL).strip()
            for server, task in tasks.items()
        }

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º raw_outputs –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è Markdown
        formatted_results = []
        for name, raw in raw_outputs.items():
            logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è {name}, –¥–ª–∏–Ω–∞: {len(raw)}")
            logger.debug(f"–ü–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤: {raw[:200]}")
            
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON
                parsed_data = json.loads(raw)
                logger.debug(f"JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –¥–ª—è {name}")
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                if isinstance(parsed_data, dict) and 'results' in parsed_data:
                    display_data = parsed_data['results']
                    logger.debug(f"–ò–∑–≤–ª–µ—á–µ–Ω—ã results –¥–ª—è {name}")
                else:
                    display_data = parsed_data
                    logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {name}")
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                formatted_json = json.dumps(display_data, indent=2, ensure_ascii=False)
                formatted_results.append(f"### {name.upper()}:\n```json\n{formatted_json}\n```")
                
            except json.JSONDecodeError as e:
                # –ï—Å–ª–∏ JSON –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –¥–ª—è {name}: {str(e)}")
                logger.debug(f"–ü—Ä–æ–±–ª–µ–º–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {name}: {raw}")
                formatted_results.append(f"### {name.upper()} (Raw output):\n```\n{raw}\n```")
            except Exception as e:
                # –õ—é–±—ã–µ –¥—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –¥–ª—è {name}: {str(e)}")
                formatted_results.append(f"### {name.upper()} (Error):\n```\n–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}\n```")
        
        markdown_output = "\n\n".join(formatted_results)

        # –ß–∏—Ç–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥
        with open(file_path, 'r', encoding='utf-8') as f_in:
            orig_code = f_in.read()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
        orig_name = os.path.basename(file_path)
        fix_prompt = f"""Below is the full source code of '{orig_name}':
```python
{orig_code}
```
Please generate a corrected version of this code, addressing all security vulnerabilities. Return only the full updated source code."""
        
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –∫–æ–¥
        fixed_code = await run_fix_agent(fix_prompt)
        
        # –û—á–∏—â–∞–µ–º –∫–æ–¥ –æ—Ç –±–ª–æ–∫–æ–≤ <think>
        cleaned_code = re.sub(r"<think>.*?</think>", "", fixed_code, flags=re.DOTALL).strip()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º diff
        diff_text = generate_simple_diff(orig_code, cleaned_code, orig_name)
        
        return markdown_output, diff_text, cleaned_code
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")
        return f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}", "", ""

async def check_all_servers():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –≤—Å–µ—Ö MCP —Å–µ—Ä–≤–µ—Ä–æ–≤"""
    unavailable_servers = []
    for server_name, config in MCP_SERVERS.items():
        if not check_port(config["port"]):
            unavailable_servers.append(f"{server_name} (–ø–æ—Ä—Ç {config['port']})")
    return unavailable_servers

def process_file_sync(file_obj, custom_checks, selected_servers):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è process_file"""
    return asyncio.run(process_file(file_obj, custom_checks, selected_servers))

# –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio
with gr.Blocks(title="Security Tools MCP Agent") as demo:
    gr.Markdown("# üîí Security Tools MCP Agent")
    
    with gr.Row():
        with gr.Column(scale=1):
            file_input = gr.File(
                label="Upload a code file",
                file_types=[".py", ".js", ".java", ".go", ".rb"]
            )
            custom_checks = gr.Textbox(
                label="Enter specific checks or tools to use (optional)",
                placeholder="e.g., SQL injection, shell injection, detect secrets"
            )
            server_checkboxes = gr.CheckboxGroup(
                choices=list(MCP_SERVERS.keys()),
                value=list(MCP_SERVERS.keys()),
                label="Select MCP Servers"
            )
            scan_button = gr.Button("Run Scan", variant="primary")
    
    with gr.Row():
        with gr.Column(scale=1):
            analysis_output = gr.Markdown(label="Security Analysis Results")
            diff_output = gr.Textbox(label="Proposed Code Fixes", lines=10)
            fixed_code_output = gr.Code(label="Fixed Code", language="python")
            download_button = gr.File(label="Download corrected file")
    
    def update_download_button(fixed_code):
        if fixed_code:
            temp_dir = tempfile.gettempdir()
            fixed_path = os.path.join(temp_dir, "fixed_code.py")
            with open(fixed_path, "w") as f:
                f.write(fixed_code)
            return fixed_path
        return None
    
    scan_button.click(
        fn=process_file_sync,
        inputs=[file_input, custom_checks, server_checkboxes],
        outputs=[analysis_output, diff_output, fixed_code_output]
    ).then(
        fn=update_download_button,
        inputs=[fixed_code_output],
        outputs=[download_button]
    )

if __name__ == "__main__":
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ MCP –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
        asyncio.run(init_all_tools())
        
        logger.info("–ó–∞–ø—É—Å–∫ Security Tools MCP Agent...")
        demo.launch(share=True)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {str(e)}")
        sys.exit(1)